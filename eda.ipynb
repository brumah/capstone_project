{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and reorganize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_stats = pd.read_pickle('training_data/split_stats_training_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_to_compare = ['batting_doubles', 'batting_triples', 'batting_homeRuns',\n",
    "                    'batting_strikeOuts', 'batting_baseOnBalls', 'batting_hits', \n",
    "                    'batting_avg', 'batting_atBats', 'batting_obp', 'batting_slg', \n",
    "                    'batting_ops', 'batting_stolenBases', 'batting_rbi', 'batting_leftOnBase',\n",
    "                    'pitching_runs', 'pitching_doubles', 'pitching_triples', \n",
    "                    'pitching_homeRuns', 'pitching_strikeOuts', 'pitching_baseOnBalls', \n",
    "                    'pitching_hits', 'pitching_atBats', 'pitching_obp', 'pitching_stolenBases', \n",
    "                    'pitching_numberOfPitches', 'pitching_era', 'pitching_inningsPitched', \n",
    "                    'pitching_earnedRuns', 'pitching_pitchesThrown', 'pitching_strikes', \n",
    "                    'pitching_rbi', 'win_percentage']\n",
    "\n",
    "df_differential = split_stats[['game_id', 'date', 'home_team_name', 'away_team_name', 'home_id', 'away_id', 'home_score', 'away_score', 'run_differential', 'home_win']].copy()\n",
    "\n",
    "for stat in stats_to_compare:\n",
    "    home_col = f'home_{stat}'\n",
    "    away_col = f'away_{stat}'\n",
    "    diff_col = f'{stat}'\n",
    "    \n",
    "    if home_col in split_stats.columns and away_col in split_stats.columns:\n",
    "        df_differential[diff_col] = split_stats[home_col] - split_stats[away_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_stats_to_compare = []\n",
    "for stat in stats_to_compare:\n",
    "    split_stats_to_compare.append(f'home_{stat}')\n",
    "    split_stats_to_compare.append(f'away_{stat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, stat in enumerate(stats_to_compare):\n",
    "    stats_to_compare[i] = f'diff_{stat}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_differential['date'] = pd.to_datetime(df_differential['date'], errors='coerce')\n",
    "early_season_removed_diff = df_differential[~df_differential['date'].dt.month.isin([3, 4])]\n",
    "for col in early_season_removed_diff.columns:\n",
    "    if early_season_removed_diff[col].dtype == 'object':\n",
    "        early_season_removed_diff[col] = pd.to_numeric(early_season_removed_diff[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_stats['date'] = pd.to_datetime(split_stats['date'], errors='coerce')\n",
    "early_season_removed = split_stats[~split_stats['date'].dt.month.isin([3, 4])]\n",
    "for col in early_season_removed.columns:\n",
    "    if early_season_removed[col].dtype == 'object':\n",
    "        early_season_removed[col] = pd.to_numeric(early_season_removed[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_season_removed['line_diff'] = (early_season_removed['run_differential'] > 1.5).astype(int)\n",
    "early_season_removed_diff['line_diff'] = (early_season_removed_diff['run_differential'] > 1.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_corr_diff_stats = [\n",
    "    'win_percentage',\n",
    "    'batting_rbi',\n",
    "    'batting_homeRuns',\n",
    "    'batting_baseOnBalls',\n",
    "    'pitching_strikeOuts',\n",
    "    'batting_ops',\n",
    "    'batting_obp',\n",
    "    'batting_slg',\n",
    "    'pitching_inningsPitched',\n",
    "    'pitching_pitchesThrown',\n",
    "    'pitching_numberOfPitches',\n",
    "    'pitching_atBats',\n",
    "    'pitching_homeRuns',\n",
    "    'pitching_doubles',\n",
    "    'pitching_era',\n",
    "    'pitching_baseOnBalls',\n",
    "    'pitching_hits',\n",
    "    'pitching_obp',\n",
    "    'pitching_earnedRuns',\n",
    "    'pitching_rbi',\n",
    "    'pitching_runs'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make eda graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = early_season_removed_diff.select_dtypes(include=['number'])\n",
    "correlation_matrix = numeric_df.corr()[['run_differential']]\n",
    "sorted_correlation_matrix = correlation_matrix.sort_values(by='run_differential', ascending=False)\n",
    "filtered_correlation_matrix = sorted_correlation_matrix[\n",
    "    ((sorted_correlation_matrix['run_differential'] > 0.1) & (sorted_correlation_matrix['run_differential'] <= 0.2)) |\n",
    "    ((sorted_correlation_matrix['run_differential'] < -0.1) & (sorted_correlation_matrix['run_differential'] >= -0.2))\n",
    "]\n",
    "purple_palette = sns.diverging_palette(270, 360, s=80, l=70, as_cmap=True)\n",
    "plt.figure(figsize=(8, max(6, len(filtered_correlation_matrix) // 2)))\n",
    "sns.heatmap(\n",
    "    filtered_correlation_matrix, annot=True, cmap=purple_palette, cbar=True, center=0,\n",
    "    annot_kws={\"size\": 10, \"weight\": \"bold\", \"color\": \"black\"}, linewidths=0.3, linecolor=\"lavender\", fmt=\".2f\"\n",
    ")\n",
    "plt.xticks(color=\"black\", fontsize=10, rotation=0, weight='bold')\n",
    "plt.yticks(color=\"black\", fontsize=10, rotation=0, weight='bold')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label('Correlation Coefficient', color=\"black\", fontsize=12, weight='bold')\n",
    "cbar.ax.tick_params(labelsize=10, color=\"black\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = early_season_removed_diff['win_percentage']\n",
    "x2 = early_season_removed_diff['pitching_obp']\n",
    "y = early_season_removed_diff['run_differential']\n",
    "slope1, intercept1 = np.polyfit(x1, y, 1)\n",
    "line1 = slope1 * x1 + intercept1\n",
    "slope2, intercept2 = np.polyfit(x2, y, 1)\n",
    "line2 = slope2 * x2 + intercept2\n",
    "scatter_color = '#CBB6E4'\n",
    "line_color = '#6A0DAD'\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6), dpi=100)\n",
    "ax1.scatter(x1, y, color=scatter_color, alpha=0.5, s=60)\n",
    "ax1.plot(x1, line1, color=line_color, linewidth=2)\n",
    "ax1.set_xlabel('Win Percentage', fontsize=12)\n",
    "ax1.set_ylabel('Run Differential', fontsize=12)\n",
    "ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "ax2.scatter(x2, y, color=scatter_color, alpha=0.5, s=60)\n",
    "ax2.plot(x2, line2, color=line_color, linewidth=2)\n",
    "ax2.set_xlabel('Pitching OBP', fontsize=12)\n",
    "ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_color = '#f3e8ff'\n",
    "original_color = '#8e44ad'\n",
    "removed_color = '#a5d6f9' \n",
    "edge_color = '#4b306e'\n",
    "grid_color = '#d0c2e6'\n",
    "plt.figure(figsize=(10, 7), facecolor=background_color)\n",
    "plt.hist(split_stats['home_win_percentage'], bins=25, color=original_color, edgecolor=edge_color, alpha=0.5, label='Original Data')\n",
    "plt.hist(early_season_removed['home_win_percentage'], bins=25, color=removed_color, edgecolor=edge_color, alpha=0.6, label='Variable Early Season Removed')\n",
    "plt.xlabel('Home Team Win Percentage', fontsize=14, color=edge_color)\n",
    "plt.ylabel('Frequency', fontsize=14, color=edge_color)\n",
    "plt.xlim(0, 1)\n",
    "plt.grid(visible=True, which='major', linestyle='--', linewidth=0.7, color=grid_color)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = early_season_removed[split_stats_to_compare]\n",
    "y = early_season_removed['line_diff']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = early_season_removed[split_stats_to_compare]\n",
    "y = early_season_removed['line_diff']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(\"Feature Importances:\", model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = early_season_removed[split_stats_to_compare]\n",
    "y = early_season_removed['line_diff']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(\"Feature Importances:\", model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = early_season_removed[split_stats_to_compare]\n",
    "y = early_season_removed['line_diff']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Logistic Regression', 'Random Forest', 'Gradient Boosting', 'Neural Network']\n",
    "accuracies = [64.0, 57.5, 58.9, 64.1]\n",
    "\n",
    "sorted_indices = sorted(range(len(accuracies)), key=lambda i: accuracies[i], reverse=True)\n",
    "models_sorted = [models[i] for i in sorted_indices]\n",
    "accuracies_sorted = [accuracies[i] for i in sorted_indices]\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(models_sorted, accuracies_sorted, color='#D7BDE2', edgecolor='black')\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 0.5, f\"{yval:.1f}%\", ha='center', va='bottom', fontsize=10)\n",
    "plt.ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "plt.ylim(55, 70)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
